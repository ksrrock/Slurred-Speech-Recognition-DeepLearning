{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torchaudio"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting torchaudio\n  Downloading torchaudio-0.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 11.5 MB/s eta 0:00:01\n\u001b[?25hCollecting torch==1.10.0\n  Downloading torch-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n\u001b[K     |████████████████████████████████| 881.9 MB 267 bytes/s a 0:00:0104\n\u001b[?25hRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch==1.10.0->torchaudio) (3.7.4.3)\nRequirement already satisfied: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch==1.10.0->torchaudio) (0.8)\n\u001b[31mERROR: torchvision 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.10.0 which is incompatible.\u001b[0m\nInstalling collected packages: torch, torchaudio\n  Attempting uninstall: torch\n    Found existing installation: torch 1.8.1\n    Uninstalling torch-1.8.1:\n      Successfully uninstalled torch-1.8.1\nSuccessfully installed torch-1.10.0 torchaudio-0.10.0\nNote: you may need to restart the kernel to use updated packages.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BukkGwnQ81U",
        "outputId": "1fec22c6-4aa0-4a8c-d5c8-4ad0b2099fd9",
        "gather": {
          "logged": 1636494899484
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing all neccessary libraries"
      ],
      "metadata": {
        "id": "JKVGDRB0fW_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings. filterwarnings(\"ignore\")\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torchaudio import transforms as tfs\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from torch.nn import Sequential as sq\n",
        "from torch.nn import Linear as lnr\n",
        "from torch import argmax as agm\n",
        "from torch.nn import Module as ml\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "kvuzLADtfVwn",
        "gather": {
          "logged": 1636497013790
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics implementation (WER and CER)"
      ],
      "metadata": {
        "id": "bhdCAHRHfaR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "  \n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        " \n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    def __init__(self):\n",
        "        self.char_map={\"'\": 0, '': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n",
        "        self.index_map={0: \"'\", 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n",
        "        \n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    \n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "N94pVVHDfeVE",
        "gather": {
          "logged": 1636497017203
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The NVIDIA System Management Interface (management and monitoring of NVIDIA GPU devices)"
      ],
      "metadata": {
        "id": "S03454e2nQ9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tue Nov  9 22:30:32 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA Tesla K80    On   | 00000001:00:00.0 Off |                    0 |\r\n| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrzOZ5BgX8Ps",
        "outputId": "57d79640-edaa-4660-b8d4-36c4c4129bb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN layer**"
      ],
      "metadata": {
        "id": "QM0mA41WneNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 3).contiguous() \n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x \n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x \n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "vpObb3vXX_El",
        "gather": {
          "logged": 1636497038325
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gated Recurrent Unit layer**"
      ],
      "metadata": {
        "id": "FUGjv3ounj3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "lMqmUQLJYBI-",
        "gather": {
          "logged": 1636497042748
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Automatic Speech Recognition Model architecture"
      ],
      "metadata": {
        "id": "cupyNOdlno-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2) \n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  \n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3]) \n",
        "        x = x.transpose(1, 2) \n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "0kIVttAsYDb5",
        "gather": {
          "logged": 1636497045053
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing Code"
      ],
      "metadata": {
        "id": "y41lkdZ-noVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IterMeter(object):\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms) \n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "    \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  \n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "  \n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "    # filename='./best_fit_model'+str(epoch)+'.h5'\n",
        "    # torch.save(model,filename)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "id": "RZ8oZecBYGFi",
        "gather": {
          "logged": 1636497049006
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters of the model"
      ],
      "metadata": {
        "id": "wGj7rLijn4Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 5\n",
        "epochs = 10\n",
        "train_url = \"train-clean-100\"\n",
        "test_url = \"test-clean\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "id": "gMG9JxM4YHaA",
        "gather": {
          "logged": 1636497054710
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "#train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "id": "0pUOYYKHYiCC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1796782785fc4eb88094ff9a8af70811",
            "a9de55cd901442b0867be3fe7d8d7976",
            "9d0ff0d587b2487aa25c04f1a2171793",
            "ccc60b9dcd734bdca18a62685682ed06",
            "e99a213eaa854b038ff3dc70f293885f",
            "19309069f93d432bab123c28de5429d4",
            "6e33f740de1d4a1ea2aaf5841cf7bb83",
            "0cff7588dbaf4782a98c1cb585d09c8f",
            "40256473f4224868a8fe75bb898f8141",
            "ba235650ac274df6b1fd30e375b29adc",
            "e37227a1c83940a0a250308d24ee4eb0",
            "ba2d2eb8c23d4093949053998458e338",
            "dd1851aa7a7e413aa2558b556a219eb9",
            "3c387c58e81f4ca4b85bc384ad108816",
            "71d278d66af741e19aa1b6ef63acfb56",
            "568024ac4dee40fb9830bc1150ba9040",
            "973afb9d80db4dcc9d86656caf556d56",
            "2fb1a9f41d94473f8280e568b5164c20",
            "aa2aeb501cee40f88b985d85bf196a61",
            "a828000f84844da48e7a5bd4bedae62a",
            "9d2ade5ab8a8427f98139961863b4da8",
            "ddd57519309745ee934c025e00087c4a"
          ]
        },
        "outputId": "4769bf0c-c156-438b-bbcc-50257c540c5e",
        "gather": {
          "logged": 1636499517218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "    \"n_cnn_layers\": 3,\n",
        "    \"n_rnn_layers\": 5,\n",
        "    \"rnn_dim\": 512,\n",
        "    \"n_class\": 29,\n",
        "    \"n_feats\": 128,\n",
        "    \"stride\":2,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs\n",
        "}\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=True,\n",
        "                            collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                            **kwargs)\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=False,\n",
        "                            collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                            **kwargs)\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "criterion = nn.CTCLoss(blank=28).to(device)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], steps_per_epoch=int(len(train_loader)),epochs=hparams['epochs'],anneal_strategy='linear')\n",
        "\n",
        "iter_meter = IterMeter()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SpeechRecognitionModel(\n  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (rescnn_layers): Sequential(\n    (0): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n  (birnn_layers): Sequential(\n    (0): BidirectionalGRU(\n      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (2): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (3): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (4): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): GELU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=29, bias=True)\n  )\n)\nNum Model Parameters 23705373\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4KvaBDgYKln",
        "outputId": "aa9a2cfc-2a80-48d7-a188-9b29c48cae12",
        "gather": {
          "logged": 1636502305526
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for model training and testing (Optional)\n",
        "\n",
        "\n",
        "> This code snippet should only be used for base model training.\n",
        "\n",
        "> Since we already have our based model trained , we will skip this part and load our trained model directly\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QxftuqFfo_tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(1, epochs+1):\n",
        "#     train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
        "#     test(model, device, test_loader, criterion, epoch, iter_meter)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "3C6FJgkro8I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the best fit model\n",
        "\n",
        "\n",
        "*   The base model for slurred speech Recognition has been trained on kaggle for 10 epoch.\n",
        "*   It has been trained on Librispeech Corpus Speech Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "fX0uozFvn--5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os \n",
        "# print(os.getcwd())\n",
        "\n",
        "loaded_model = torch.load('/mnt/batch/tasks/shared/LS_root/mounts/clusters/shivam1234/code/Users/kshivamranjan.cse18/Best-Fit-TrainedModel/best_fit_model_final.h5')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/shivam1234/code/Users/kshivamranjan.cse18\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "id": "iGALiIQhZMwO",
        "gather": {
          "logged": 1636502920233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SpeechRecognitionModel(\n  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (rescnn_layers): Sequential(\n    (0): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n  (birnn_layers): Sequential(\n    (0): BidirectionalGRU(\n      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (2): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (3): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (4): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): GELU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=29, bias=True)\n  )\n)\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6gIyA4YgpQ",
        "outputId": "a174e1c2-0547-470a-f0d6-a595ea3a0d3b",
        "gather": {
          "logged": 1636502945674
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing our loaded base model"
      ],
      "metadata": {
        "id": "NEXebGeypl03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(loaded_model, device, test_loader, criterion, 1, iter_meter)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nevaluating...\nTest set: Average loss: 0.4613, Average CER: 0.100144 Average WER: 0.1190\n\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUkhKqGGpxol",
        "outputId": "aeb6b30b-c395-4980-c465-badbf7ec2549",
        "gather": {
          "logged": 1636504611203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Tuple, Union\n",
        "from pathlib import Path\n",
        "import torchaudio\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def load_librispeech_item(fileid,path,ext_audio,ext_txt):\n",
        "    speaker_id, chapter_id, utterance_id = fileid.split(\"-\")\n",
        "\n",
        "    file_text = speaker_id + \"-\" + chapter_id + ext_txt\n",
        "    file_text = os.path.join(path, speaker_id, chapter_id, file_text)\n",
        "\n",
        "    fileid_audio = speaker_id + \"-\" + chapter_id + \"-\" + utterance_id\n",
        "    file_audio = fileid_audio + ext_audio\n",
        "    file_audio = os.path.join(path, speaker_id, chapter_id, file_audio)\n",
        "\n",
        "    waveform, sample_rate = torchaudio.load(file_audio)\n",
        "\n",
        "    with open(file_text) as ft:\n",
        "        for line in ft:\n",
        "            fileid_text, utterance = line.strip().split(\" \", 1)\n",
        "            if fileid_audio == fileid_text:\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Translation not found for \" + fileid_audio)\n",
        "\n",
        "    return (waveform,sample_rate,utterance,int(speaker_id),int(chapter_id),int(utterance_id),)\n"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "id": "_p8C5mpLbm20",
        "gather": {
          "logged": 1636504998967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom class for loading Slurred Speech Test Dataset in Pytorch"
      ],
      "metadata": {
        "id": "rNeuTm-IFr8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset): \n",
        "    _ext_txt = \".trans.txt\"\n",
        "    _ext_audio = \".flac\"\n",
        "    def __init__(self):\n",
        "        self._path=\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/shivam1234/code/Users/kshivamranjan.cse18/SlurredSpeech_Dataset_Test\"\n",
        "        self._walker=['1-2-0000', '1-2-0001', '1-2-0002', '1-2-0003', '1-2-0004', '1-2-0005', '1-2-0006', '1-2-0007', '1-2-0008', '1-2-0009', '1-2-0010', '1-2-0011', '1-2-0012', '1-2-0013', '1-2-0014', '1-2-0015', '1-2-0016', '1-2-0017', '1-2-0018', '1-2-0019', '1-2-0020', '1-2-0021', '1-2-0022', '1-2-0023', '1-2-0024', '1-2-0025', '1-2-0026', '1-2-0027', '1-2-0028', '1-2-0029', '1-2-0030', '1-2-0031', '1-2-0032', '1-2-0033', '1-2-0034', '1-2-0035', '1-2-0036', '1-2-0037', '1-2-0038', '1-2-0039', '1-2-0040', '1-2-0041', '1-2-0042', '1-2-0043', '1-2-0044', '1-2-0045', '1-2-0046', '1-2-0047', '1-2-0048', '1-2-0049', '1-2-0050', '1-2-0051', '1-2-0052', '1-2-0053', '1-2-0054', '1-2-0055', '1-2-0056', '1-2-0057', '1-2-0058', '1-2-0059', '1-2-0060', '1-2-0061', '1-2-0062', '1-2-0063', '1-2-0064', '1-2-0065', '1-2-0066', '1-2-0067', '1-2-0068', '1-2-0069', '1-2-0070', '1-2-0071', '1-2-0072', '1-2-0073', '1-2-0074', '1-2-0075', '1-2-0076', '1-2-0077', '1-2-0078', '1-2-0079', '1-2-0080', '1-2-0081', '1-2-0082', '1-2-0083', '1-2-0084', '1-2-0085', '1-2-0086', '1-2-0087', '1-2-0088', '1-2-0089', '1-2-0090', '1-2-0091', '1-2-0092', '1-2-0093', '1-2-0094', '1-2-0095', '1-2-0096', '1-2-0097', '1-2-0098', '1-2-0099']\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        fileid = self._walker[n]\n",
        "        return load_librispeech_item(fileid, self._path, self._ext_audio, self._ext_txt)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._walker)   \n",
        "    \n",
        "    \n",
        "testDataset_slurred_speech=TestDataset()"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "id": "w1AWy9snF1WZ",
        "gather": {
          "logged": 1636505079704
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom class for loading Slurred Speech Train Dataset in Pytorch"
      ],
      "metadata": {
        "id": "Z-yHQfJhF4Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset): \n",
        "    _ext_txt = \".trans.txt\"\n",
        "    _ext_audio = \".flac\"\n",
        "    def __init__(self):\n",
        "        self._path=\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/shivam1234/code/Users/kshivamranjan.cse18/SlurredSpeech_Dataset_Train\"\n",
        "        self._walker=['1-2-0000', '1-2-0001', '1-2-0002', '1-2-0003', '1-2-0004', '1-2-0005', '1-2-0006', '1-2-0007', '1-2-0008', '1-2-0009', '1-2-0010', '1-2-0011', '1-2-0012', '1-2-0013', '1-2-0014', '1-2-0015', '1-2-0016', '1-2-0017', '1-2-0018', '1-2-0019', '1-2-0020', '1-2-0021', '1-2-0022', '1-2-0023', '1-2-0024', '1-2-0025', '1-2-0026', '1-2-0027', '1-2-0028', '1-2-0029', '1-2-0030', '1-2-0031', '1-2-0032', '1-2-0033', '1-2-0034', '1-2-0035', '1-2-0036', '1-2-0037', '1-2-0038', '1-2-0039', '1-2-0040', '1-2-0041', '1-2-0042', '1-2-0043', '1-2-0044', '1-2-0045', '1-2-0046', '1-2-0047', '1-2-0048', '1-2-0049', '1-2-0050', '1-2-0051', '1-2-0052', '1-2-0053', '1-2-0054', '1-2-0055', '1-2-0056', '1-2-0057', '1-2-0058', '1-2-0059', '1-2-0060', '1-2-0061', '1-2-0062', '1-2-0063', '1-2-0064', '1-2-0065', '1-2-0066', '1-2-0067', '1-2-0068', '1-2-0069', '1-2-0070', '1-2-0071', '1-2-0072', '1-2-0073', '1-2-0074', '1-2-0075', '1-2-0076', '1-2-0077', '1-2-0078', '1-2-0079', '1-2-0080', '1-2-0081', '1-2-0082', '1-2-0083', '1-2-0084', '1-2-0085', '1-2-0086', '1-2-0087', '1-2-0088', '1-2-0089', '1-2-0090', '1-2-0091', '1-2-0092', '1-2-0093', '1-2-0094', '1-2-0095', '1-2-0096', '1-2-0097', '1-2-0098', '1-2-0099']\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        fileid = self._walker[n]\n",
        "        return load_librispeech_item(fileid, self._path, self._ext_audio, self._ext_txt)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._walker)   \n",
        "    \n",
        "    \n",
        "trainDataset_slurred_speech=TrainDataset()"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "id": "32vqme6tF_9D",
        "gather": {
          "logged": 1636505082668
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "testDataLoaderSlurred = data.DataLoader(dataset=testDataset_slurred_speech,batch_size=hparams['batch_size'],shuffle=False,collate_fn=lambda x: data_processing(x, 'valid'),**kwargs)\n",
        "trainDataLoderSlurred = data.DataLoader(dataset=trainDataset_slurred_speech,batch_size=hparams['batch_size'],shuffle=False,collate_fn=lambda x: data_processing(x, 'valid'),**kwargs)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "id": "DK8WOvO3bnAo",
        "gather": {
          "logged": 1636505085291
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing our base model before fine tuning on slurred speech dataset"
      ],
      "metadata": {
        "id": "7ShzeIQjw7Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(loaded_model, device, testDataLoaderSlurred, criterion, 1, iter_meter)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nevaluating...\nTest set: Average loss: 4.3406, Average CER: 0.673538 Average WER: 0.6378\n\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpIbdbfbnGl",
        "outputId": "21741f77-2c8b-4f34-fa37-fb12c5adac3a",
        "gather": {
          "logged": 1636505109558
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning Training and Testing"
      ],
      "metadata": {
        "id": "L2ORmkDudhKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IterMeter(object):\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "def train_transfer_learning(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms) \n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "    \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test_transfer_learning(model, device, test_loader, criterion, epoch, iter_meter,losses,character_error_rates,word_error_rates):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  \n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    losses.append(test_loss)\n",
        "    character_error_rates.append(avg_cer)\n",
        "    word_error_rates.append(avg_wer)\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "    # filename='./best_fit_model'+str(epoch)+'.h5'\n",
        "    # torch.save(model,filename)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "id": "rqh4hqZrdgJD",
        "gather": {
          "logged": 1636505192397
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying transfer learning"
      ],
      "metadata": {
        "id": "WS6xjIOzxQLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_learning_type1(pre_trained_model):\n",
        "  hparams = {\"learning_rate\": 5e-4,\"batch_size\": 5,\"epochs\": 20}\n",
        "  opti = optim.AdamW(pre_trained_model.parameters(), hparams['learning_rate'])\n",
        "  crit = nn.CTCLoss(blank=28).to(device)\n",
        "  sche = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], steps_per_epoch=int(len(trainDataLoderSlurred)),epochs=hparams['epochs'],anneal_strategy='linear')\n",
        "  iter = IterMeter()\n",
        "  losses=[]\n",
        "  character_error_rates=[]\n",
        "  word_error_rates=[]\n",
        "  for epoch in range(1, hparams['epochs']+1):\n",
        "    train_transfer_learning(pre_trained_model, device, trainDataLoderSlurred, crit, opti, sche, epoch, iter)\n",
        "    test_transfer_learning(pre_trained_model, device, testDataLoaderSlurred, crit, epoch, iter,losses,character_error_rates,word_error_rates)\n",
        "\n",
        "transfer_learning_type1(loaded_model)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train Epoch: 1 [0/100 (0%)]\tLoss: 4.572165\n\nevaluating...\nTest set: Average loss: 2.8773, Average CER: 0.996303 Average WER: 0.9633\n\nTrain Epoch: 2 [0/100 (0%)]\tLoss: 2.746296\n\nevaluating...\nTest set: Average loss: 3.0265, Average CER: 1.000000 Average WER: 0.9665\n\nTrain Epoch: 3 [0/100 (0%)]\tLoss: 2.736920\n\nevaluating...\nTest set: Average loss: 2.7813, Average CER: 0.920148 Average WER: 0.9160\n\nTrain Epoch: 4 [0/100 (0%)]\tLoss: 2.731049\n\nevaluating...\nTest set: Average loss: 2.7536, Average CER: 0.912859 Average WER: 0.9086\n\nTrain Epoch: 5 [0/100 (0%)]\tLoss: 2.723264\n\nevaluating...\nTest set: Average loss: 2.9162, Average CER: 0.934601 Average WER: 0.9204\n\nTrain Epoch: 6 [0/100 (0%)]\tLoss: 2.693128\n\nevaluating...\nTest set: Average loss: 2.7330, Average CER: 0.861749 Average WER: 0.6853\n\nTrain Epoch: 7 [0/100 (0%)]\tLoss: 2.654252\n\nevaluating...\nTest set: Average loss: 2.7603, Average CER: 0.911413 Average WER: 0.6834\n\nTrain Epoch: 8 [0/100 (0%)]\tLoss: 2.752574\n\nevaluating...\nTest set: Average loss: 2.8538, Average CER: 0.911482 Average WER: 0.6725\n\nTrain Epoch: 9 [0/100 (0%)]\tLoss: 2.744261\n\nevaluating...\nTest set: Average loss: 2.7751, Average CER: 0.933605 Average WER: 0.7083\n\nTrain Epoch: 10 [0/100 (0%)]\tLoss: 2.666149\n\nevaluating...\nTest set: Average loss: 2.7234, Average CER: 0.873681 Average WER: 0.6653\n\nTrain Epoch: 11 [0/100 (0%)]\tLoss: 2.663043\n\nevaluating...\nTest set: Average loss: 2.6510, Average CER: 0.811800 Average WER: 0.6350\n\nTrain Epoch: 12 [0/100 (0%)]\tLoss: 2.640693\n\nevaluating...\nTest set: Average loss: 2.6330, Average CER: 0.800893 Average WER: 0.6584\n\nTrain Epoch: 13 [0/100 (0%)]\tLoss: 2.634411\n\nevaluating...\nTest set: Average loss: 2.6552, Average CER: 0.807592 Average WER: 0.7425\n\nTrain Epoch: 14 [0/100 (0%)]\tLoss: 2.689269\n\nevaluating...\nTest set: Average loss: 2.7990, Average CER: 0.863212 Average WER: 0.7373\n\nTrain Epoch: 15 [0/100 (0%)]\tLoss: 2.749339\n\nevaluating...\nTest set: Average loss: 2.6354, Average CER: 0.800756 Average WER: 0.7242\n\nTrain Epoch: 16 [0/100 (0%)]\tLoss: 2.695780\n\nevaluating...\nTest set: Average loss: 2.6165, Average CER: 0.806744 Average WER: 0.6137\n\nTrain Epoch: 17 [0/100 (0%)]\tLoss: 2.711543\n\nevaluating...\nTest set: Average loss: 2.5942, Average CER: 0.796298 Average WER: 0.6074\n\nTrain Epoch: 18 [0/100 (0%)]\tLoss: 2.669972\n\nevaluating...\nTest set: Average loss: 2.6090, Average CER: 0.788024 Average WER: 0.6083\n\nTrain Epoch: 19 [0/100 (0%)]\tLoss: 2.683589\n\nevaluating...\nTest set: Average loss: 2.6111, Average CER: 0.745286 Average WER: 0.6040\n\nTrain Epoch: 20 [0/100 (0%)]\tLoss: 2.710570\n\nevaluating...\nTest set: Average loss: 2.6979, Average CER: 0.691931 Average WER: 0.6661\n\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "id": "K3pvzxRrBvF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214ff1a1-6d30-4f9a-9934-ab0587e1dda8",
        "gather": {
          "logged": 1636506044216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params=loaded_model.state_dict()\n",
        "print(params.keys())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "odict_keys(['cnn.weight', 'cnn.bias', 'rescnn_layers.0.cnn1.weight', 'rescnn_layers.0.cnn1.bias', 'rescnn_layers.0.cnn2.weight', 'rescnn_layers.0.cnn2.bias', 'rescnn_layers.0.layer_norm1.layer_norm.weight', 'rescnn_layers.0.layer_norm1.layer_norm.bias', 'rescnn_layers.0.layer_norm2.layer_norm.weight', 'rescnn_layers.0.layer_norm2.layer_norm.bias', 'rescnn_layers.1.cnn1.weight', 'rescnn_layers.1.cnn1.bias', 'rescnn_layers.1.cnn2.weight', 'rescnn_layers.1.cnn2.bias', 'rescnn_layers.1.layer_norm1.layer_norm.weight', 'rescnn_layers.1.layer_norm1.layer_norm.bias', 'rescnn_layers.1.layer_norm2.layer_norm.weight', 'rescnn_layers.1.layer_norm2.layer_norm.bias', 'rescnn_layers.2.cnn1.weight', 'rescnn_layers.2.cnn1.bias', 'rescnn_layers.2.cnn2.weight', 'rescnn_layers.2.cnn2.bias', 'rescnn_layers.2.layer_norm1.layer_norm.weight', 'rescnn_layers.2.layer_norm1.layer_norm.bias', 'rescnn_layers.2.layer_norm2.layer_norm.weight', 'rescnn_layers.2.layer_norm2.layer_norm.bias', 'fully_connected.weight', 'fully_connected.bias', 'birnn_layers.0.BiGRU.weight_ih_l0', 'birnn_layers.0.BiGRU.weight_hh_l0', 'birnn_layers.0.BiGRU.bias_ih_l0', 'birnn_layers.0.BiGRU.bias_hh_l0', 'birnn_layers.0.BiGRU.weight_ih_l0_reverse', 'birnn_layers.0.BiGRU.weight_hh_l0_reverse', 'birnn_layers.0.BiGRU.bias_ih_l0_reverse', 'birnn_layers.0.BiGRU.bias_hh_l0_reverse', 'birnn_layers.0.layer_norm.weight', 'birnn_layers.0.layer_norm.bias', 'birnn_layers.1.BiGRU.weight_ih_l0', 'birnn_layers.1.BiGRU.weight_hh_l0', 'birnn_layers.1.BiGRU.bias_ih_l0', 'birnn_layers.1.BiGRU.bias_hh_l0', 'birnn_layers.1.BiGRU.weight_ih_l0_reverse', 'birnn_layers.1.BiGRU.weight_hh_l0_reverse', 'birnn_layers.1.BiGRU.bias_ih_l0_reverse', 'birnn_layers.1.BiGRU.bias_hh_l0_reverse', 'birnn_layers.1.layer_norm.weight', 'birnn_layers.1.layer_norm.bias', 'birnn_layers.2.BiGRU.weight_ih_l0', 'birnn_layers.2.BiGRU.weight_hh_l0', 'birnn_layers.2.BiGRU.bias_ih_l0', 'birnn_layers.2.BiGRU.bias_hh_l0', 'birnn_layers.2.BiGRU.weight_ih_l0_reverse', 'birnn_layers.2.BiGRU.weight_hh_l0_reverse', 'birnn_layers.2.BiGRU.bias_ih_l0_reverse', 'birnn_layers.2.BiGRU.bias_hh_l0_reverse', 'birnn_layers.2.layer_norm.weight', 'birnn_layers.2.layer_norm.bias', 'birnn_layers.3.BiGRU.weight_ih_l0', 'birnn_layers.3.BiGRU.weight_hh_l0', 'birnn_layers.3.BiGRU.bias_ih_l0', 'birnn_layers.3.BiGRU.bias_hh_l0', 'birnn_layers.3.BiGRU.weight_ih_l0_reverse', 'birnn_layers.3.BiGRU.weight_hh_l0_reverse', 'birnn_layers.3.BiGRU.bias_ih_l0_reverse', 'birnn_layers.3.BiGRU.bias_hh_l0_reverse', 'birnn_layers.3.layer_norm.weight', 'birnn_layers.3.layer_norm.bias', 'birnn_layers.4.BiGRU.weight_ih_l0', 'birnn_layers.4.BiGRU.weight_hh_l0', 'birnn_layers.4.BiGRU.bias_ih_l0', 'birnn_layers.4.BiGRU.bias_hh_l0', 'birnn_layers.4.BiGRU.weight_ih_l0_reverse', 'birnn_layers.4.BiGRU.weight_hh_l0_reverse', 'birnn_layers.4.BiGRU.bias_ih_l0_reverse', 'birnn_layers.4.BiGRU.bias_hh_l0_reverse', 'birnn_layers.4.layer_norm.weight', 'birnn_layers.4.layer_norm.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias'])\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX1-zLBXBI3H",
        "outputId": "cc7eca70-0b48-4e60-ce3f-13b463a57e97",
        "gather": {
          "logged": 1636506044654
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses=[]\n",
        "character_error_rates=[]\n",
        "word_error_rates=[]\n",
        "def transfer_learning(pre_trained_model):\n",
        "  learning_rate = 5e-4\n",
        "  batch_size = 5\n",
        "  epochs = 20\n",
        "  params=loaded_model.state_dict()\n",
        "  print(params.keys())\n",
        "  loaded_model.cnn.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[0].cnn1.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[0].cnn2.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[0].layer_norm1.layer_norm.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[0].layer_norm2.layer_norm.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[1].cnn1.weight.requires_grad=False\n",
        "  loaded_model.rescnn_layers[1].cnn2.weight.requires_grad=False\n",
        "  hparams = {\"n_cnn_layers\": 3,\"n_rnn_layers\": 5,\"rnn_dim\": 512,\"n_class\": 29,\"n_feats\": 128,\"stride\":2,\"dropout\": 0.1,\"learning_rate\": learning_rate,\"batch_size\": batch_size,\"epochs\": epochs}\n",
        "  opti = optim.AdamW(pre_trained_model.parameters(), hparams['learning_rate'])\n",
        "  crit = nn.CTCLoss(blank=28).to(device)\n",
        "  sche = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], steps_per_epoch=int(len(trainDataLoderSlurred)),epochs=hparams['epochs'],anneal_strategy='linear')\n",
        "  iter = IterMeter()\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    train_transfer_learning(pre_trained_model, device, trainDataLoderSlurred, crit, opti, sche, epoch, iter)\n",
        "    test_transfer_learning(pre_trained_model, device, testDataLoaderSlurred, crit, epoch, iter,losses,character_error_rates,word_error_rates)\n",
        "\n",
        "transfer_learning(loaded_model)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "odict_keys(['cnn.weight', 'cnn.bias', 'rescnn_layers.0.cnn1.weight', 'rescnn_layers.0.cnn1.bias', 'rescnn_layers.0.cnn2.weight', 'rescnn_layers.0.cnn2.bias', 'rescnn_layers.0.layer_norm1.layer_norm.weight', 'rescnn_layers.0.layer_norm1.layer_norm.bias', 'rescnn_layers.0.layer_norm2.layer_norm.weight', 'rescnn_layers.0.layer_norm2.layer_norm.bias', 'rescnn_layers.1.cnn1.weight', 'rescnn_layers.1.cnn1.bias', 'rescnn_layers.1.cnn2.weight', 'rescnn_layers.1.cnn2.bias', 'rescnn_layers.1.layer_norm1.layer_norm.weight', 'rescnn_layers.1.layer_norm1.layer_norm.bias', 'rescnn_layers.1.layer_norm2.layer_norm.weight', 'rescnn_layers.1.layer_norm2.layer_norm.bias', 'rescnn_layers.2.cnn1.weight', 'rescnn_layers.2.cnn1.bias', 'rescnn_layers.2.cnn2.weight', 'rescnn_layers.2.cnn2.bias', 'rescnn_layers.2.layer_norm1.layer_norm.weight', 'rescnn_layers.2.layer_norm1.layer_norm.bias', 'rescnn_layers.2.layer_norm2.layer_norm.weight', 'rescnn_layers.2.layer_norm2.layer_norm.bias', 'fully_connected.weight', 'fully_connected.bias', 'birnn_layers.0.BiGRU.weight_ih_l0', 'birnn_layers.0.BiGRU.weight_hh_l0', 'birnn_layers.0.BiGRU.bias_ih_l0', 'birnn_layers.0.BiGRU.bias_hh_l0', 'birnn_layers.0.BiGRU.weight_ih_l0_reverse', 'birnn_layers.0.BiGRU.weight_hh_l0_reverse', 'birnn_layers.0.BiGRU.bias_ih_l0_reverse', 'birnn_layers.0.BiGRU.bias_hh_l0_reverse', 'birnn_layers.0.layer_norm.weight', 'birnn_layers.0.layer_norm.bias', 'birnn_layers.1.BiGRU.weight_ih_l0', 'birnn_layers.1.BiGRU.weight_hh_l0', 'birnn_layers.1.BiGRU.bias_ih_l0', 'birnn_layers.1.BiGRU.bias_hh_l0', 'birnn_layers.1.BiGRU.weight_ih_l0_reverse', 'birnn_layers.1.BiGRU.weight_hh_l0_reverse', 'birnn_layers.1.BiGRU.bias_ih_l0_reverse', 'birnn_layers.1.BiGRU.bias_hh_l0_reverse', 'birnn_layers.1.layer_norm.weight', 'birnn_layers.1.layer_norm.bias', 'birnn_layers.2.BiGRU.weight_ih_l0', 'birnn_layers.2.BiGRU.weight_hh_l0', 'birnn_layers.2.BiGRU.bias_ih_l0', 'birnn_layers.2.BiGRU.bias_hh_l0', 'birnn_layers.2.BiGRU.weight_ih_l0_reverse', 'birnn_layers.2.BiGRU.weight_hh_l0_reverse', 'birnn_layers.2.BiGRU.bias_ih_l0_reverse', 'birnn_layers.2.BiGRU.bias_hh_l0_reverse', 'birnn_layers.2.layer_norm.weight', 'birnn_layers.2.layer_norm.bias', 'birnn_layers.3.BiGRU.weight_ih_l0', 'birnn_layers.3.BiGRU.weight_hh_l0', 'birnn_layers.3.BiGRU.bias_ih_l0', 'birnn_layers.3.BiGRU.bias_hh_l0', 'birnn_layers.3.BiGRU.weight_ih_l0_reverse', 'birnn_layers.3.BiGRU.weight_hh_l0_reverse', 'birnn_layers.3.BiGRU.bias_ih_l0_reverse', 'birnn_layers.3.BiGRU.bias_hh_l0_reverse', 'birnn_layers.3.layer_norm.weight', 'birnn_layers.3.layer_norm.bias', 'birnn_layers.4.BiGRU.weight_ih_l0', 'birnn_layers.4.BiGRU.weight_hh_l0', 'birnn_layers.4.BiGRU.bias_ih_l0', 'birnn_layers.4.BiGRU.bias_hh_l0', 'birnn_layers.4.BiGRU.weight_ih_l0_reverse', 'birnn_layers.4.BiGRU.weight_hh_l0_reverse', 'birnn_layers.4.BiGRU.bias_ih_l0_reverse', 'birnn_layers.4.BiGRU.bias_hh_l0_reverse', 'birnn_layers.4.layer_norm.weight', 'birnn_layers.4.layer_norm.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias'])\nTrain Epoch: 1 [0/100 (0%)]\tLoss: 2.441228\n\nevaluating...\nTest set: Average loss: 2.4085, Average CER: 0.725886 Average WER: 0.5972\n\n\nevaluating...\nTest set: Average loss: 2.5107, Average CER: 0.806872 Average WER: 0.7307\n\nTrain Epoch: 3 [0/100 (0%)]\tLoss: 2.431593\n\nevaluating...\nTest set: Average loss: 2.4192, Average CER: 0.779233 Average WER: 0.6495\n\nTrain Epoch: 4 [0/100 (0%)]\tLoss: 2.378661\n\nevaluating...\nTest set: Average loss: 2.2871, Average CER: 0.714135 Average WER: 0.6936\n\nTrain Epoch: 5 [0/100 (0%)]\tLoss: 2.244297\n\nevaluating...\nTest set: Average loss: 2.2087, Average CER: 0.706094 Average WER: 0.6679\n\nTrain Epoch: 6 [0/100 (0%)]\tLoss: 2.149308\n\nevaluating...\nTest set: Average loss: 2.1658, Average CER: 0.667033 Average WER: 0.5837\n\nTrain Epoch: 7 [0/100 (0%)]\tLoss: 2.068089\n\nevaluating...\nTest set: Average loss: 2.0631, Average CER: 0.650324 Average WER: 0.5685\n\nTrain Epoch: 8 [0/100 (0%)]\tLoss: 1.969098\n\nevaluating...\nTest set: Average loss: 2.0366, Average CER: 0.609307 Average WER: 0.5421\n\nTrain Epoch: 9 [0/100 (0%)]\tLoss: 1.868043\n\nevaluating...\nTest set: Average loss: 1.9828, Average CER: 0.599981 Average WER: 0.5399\n\nTrain Epoch: 10 [0/100 (0%)]\tLoss: 1.803443\n\nevaluating...\nTest set: Average loss: 1.8533, Average CER: 0.559434 Average WER: 0.5125\n\nTrain Epoch: 11 [0/100 (0%)]\tLoss: 1.650594\n\nevaluating...\nTest set: Average loss: 1.8242, Average CER: 0.562329 Average WER: 0.5153\n\nTrain Epoch: 12 [0/100 (0%)]\tLoss: 1.579584\n\nevaluating...\nTest set: Average loss: 1.7470, Average CER: 0.576714 Average WER: 0.5123\n\nTrain Epoch: 13 [0/100 (0%)]\tLoss: 1.594179\n\nevaluating...\nTest set: Average loss: 1.7293, Average CER: 0.530028 Average WER: 0.4959\n\nTrain Epoch: 14 [0/100 (0%)]\tLoss: 1.551427\n\nevaluating...\nTest set: Average loss: 1.7259, Average CER: 0.495591 Average WER: 0.4849\n\nTrain Epoch: 15 [0/100 (0%)]\tLoss: 1.455841\n\nevaluating...\nTest set: Average loss: 1.6363, Average CER: 0.537012 Average WER: 0.4964\n\nTrain Epoch: 16 [0/100 (0%)]\tLoss: 1.355353\n\nevaluating...\nTest set: Average loss: 1.6038, Average CER: 0.501933 Average WER: 0.4772\n\nTrain Epoch: 17 [0/100 (0%)]\tLoss: 1.486730\n\nevaluating...\nTest set: Average loss: 1.5054, Average CER: 0.480668 Average WER: 0.4841\n\nTrain Epoch: 18 [0/100 (0%)]\tLoss: 1.315587\n\nevaluating...\nTest set: Average loss: 1.4395, Average CER: 0.478923 Average WER: 0.4563\n\nTrain Epoch: 19 [0/100 (0%)]\tLoss: 1.314250\n\nevaluating...\nTest set: Average loss: 1.3831, Average CER: 0.439714 Average WER: 0.4342\n\nTrain Epoch: 20 [0/100 (0%)]\tLoss: 1.232649\n\nevaluating...\nTest set: Average loss: 1.2834, Average CER: 0.445195 Average WER: 0.4291\n\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDR-tXqi2j0N",
        "outputId": "b25952fd-175a-4a0e-83ff-d6e92aa20ee3",
        "gather": {
          "logged": 1636507426098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "epochs=[i for i in range(1,21)]\n",
        "y = losses\n",
        "x = epochs\n",
        "plt.xlabel(\"Epochs\") \n",
        "plt.ylabel(\"Loss\") \n",
        "plt.title(\"Loss Vs Epoch\") \n",
        "plt.plot(x, y) \n",
        "plt.xticks(x)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 40,
      "metadata": {
        "id": "8bTqmSurwWol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "7ff397b3-768f-4dad-9fb6-194599b57932",
        "gather": {
          "logged": 1636507642773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "epochs=[i for i in range(1,21)]\n",
        "y1 = word_error_rates\n",
        "y2=character_error_rates\n",
        "x = epochs\n",
        "plt.xlabel(\"Epochs\") \n",
        "plt.ylabel(\"Error Rate\") \n",
        "plt.title(\"Error Rates Vs Epoch\") \n",
        "plt.plot(x, y1,label='WER')\n",
        "plt.plot(x,y2,label='CER') \n",
        "plt.ylim(0.1,1.0)\n",
        "plt.xticks(x)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "nI-2BlNQfdKI",
        "outputId": "602d8b56-9425-4a2d-8053-76472ea58ceb",
        "gather": {
          "logged": 1636507666894
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Transcript of single audio file using Trained model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_TestDataset_class(Dataset): \r\n",
        "    _ext_txt = \".trans.txt\"\r\n",
        "    _ext_audio = \".flac\"\r\n",
        "    def __init__(self):\r\n",
        "        self._path=\"path to test data folder\"\r\n",
        "        self._walker=[] # list of audio file names\r\n",
        "    def __getitem__(self, n):\r\n",
        "        fileid = self._walker[n]\r\n",
        "        return load_librispeech_item(fileid, self._path, self._ext_audio, self._ext_txt)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self._walker)   \r\n",
        "    \r\n",
        "    \r\n",
        "single_audio_dataloader=custom_TestDataset_class()"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "id": "VK8p0AzafdTB",
        "gather": {
          "logged": 1636507673387
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_audio_test(model, device, test_loader, iter_meter):\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for i, _data in enumerate(test_loader):\r\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \r\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\r\n",
        "            output = model(spectrograms)  \r\n",
        "            output = F.log_softmax(output, dim=2)\r\n",
        "            output = output.transpose(0, 1)\r\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\r\n",
        "            print(decoded_preds)\r\n",
        "\r\n",
        "single_audio_test(loaded_model, device, single_audio_dataloader, iter)\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "BTP Part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19309069f93d432bab123c28de5429d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "973afb9d80db4dcc9d86656caf556d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a828000f84844da48e7a5bd4bedae62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "3c387c58e81f4ca4b85bc384ad108816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_2fb1a9f41d94473f8280e568b5164c20",
            "value": "100%",
            "style": "IPY_MODEL_973afb9d80db4dcc9d86656caf556d56",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "e99a213eaa854b038ff3dc70f293885f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_e37227a1c83940a0a250308d24ee4eb0",
            "value": " 5.95G/5.95G [05:08&lt;00:00, 26.3MB/s]",
            "style": "IPY_MODEL_ba235650ac274df6b1fd30e375b29adc",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "40256473f4224868a8fe75bb898f8141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "1796782785fc4eb88094ff9a8af70811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HBoxView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_a9de55cd901442b0867be3fe7d8d7976",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d0ff0d587b2487aa25c04f1a2171793",
              "IPY_MODEL_ccc60b9dcd734bdca18a62685682ed06",
              "IPY_MODEL_e99a213eaa854b038ff3dc70f293885f"
            ]
          }
        },
        "71d278d66af741e19aa1b6ef63acfb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "FloatProgressModel",
            "_model_module": "@jupyter-widgets/controls",
            "max": 346663984,
            "bar_style": "success",
            "_view_name": "ProgressView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_a828000f84844da48e7a5bd4bedae62a",
            "orientation": "horizontal",
            "value": 346663984,
            "style": "IPY_MODEL_aa2aeb501cee40f88b985d85bf196a61",
            "min": 0,
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "6e33f740de1d4a1ea2aaf5841cf7bb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "dd1851aa7a7e413aa2558b556a219eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "aa2aeb501cee40f88b985d85bf196a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "ProgressStyleModel",
            "_model_module": "@jupyter-widgets/controls",
            "description_width": "",
            "_view_name": "StyleView",
            "_view_module": "@jupyter-widgets/base",
            "_view_count": null,
            "bar_color": null,
            "_model_module_version": "1.5.0"
          }
        },
        "568024ac4dee40fb9830bc1150ba9040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_ddd57519309745ee934c025e00087c4a",
            "value": " 331M/331M [00:14&lt;00:00, 27.7MB/s]",
            "style": "IPY_MODEL_9d2ade5ab8a8427f98139961863b4da8",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "ddd57519309745ee934c025e00087c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "a9de55cd901442b0867be3fe7d8d7976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "ba235650ac274df6b1fd30e375b29adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccc60b9dcd734bdca18a62685682ed06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "FloatProgressModel",
            "_model_module": "@jupyter-widgets/controls",
            "max": 6387309499,
            "bar_style": "success",
            "_view_name": "ProgressView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_40256473f4224868a8fe75bb898f8141",
            "orientation": "horizontal",
            "value": 6387309499,
            "style": "IPY_MODEL_0cff7588dbaf4782a98c1cb585d09c8f",
            "min": 0,
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "9d2ade5ab8a8427f98139961863b4da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba2d2eb8c23d4093949053998458e338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HBoxView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_dd1851aa7a7e413aa2558b556a219eb9",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c387c58e81f4ca4b85bc384ad108816",
              "IPY_MODEL_71d278d66af741e19aa1b6ef63acfb56",
              "IPY_MODEL_568024ac4dee40fb9830bc1150ba9040"
            ]
          }
        },
        "2fb1a9f41d94473f8280e568b5164c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "0cff7588dbaf4782a98c1cb585d09c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "ProgressStyleModel",
            "_model_module": "@jupyter-widgets/controls",
            "description_width": "",
            "_view_name": "StyleView",
            "_view_module": "@jupyter-widgets/base",
            "_view_count": null,
            "bar_color": null,
            "_model_module_version": "1.5.0"
          }
        },
        "e37227a1c83940a0a250308d24ee4eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "9d0ff0d587b2487aa25c04f1a2171793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_6e33f740de1d4a1ea2aaf5841cf7bb83",
            "value": "100%",
            "style": "IPY_MODEL_19309069f93d432bab123c28de5429d4",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}