{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTP",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81c0dc5cd8ac477cbc425578cc09e349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8df098629d5d4c169252983947a16421",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_122c48c556e5404cbaf0f63fec20fd0e",
              "IPY_MODEL_9715107e845241b7b6c683180f7c3b91",
              "IPY_MODEL_a3f087b1e5fd4e1381ec0e1b80801b91"
            ]
          }
        },
        "8df098629d5d4c169252983947a16421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "122c48c556e5404cbaf0f63fec20fd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_210d445576ec438096e8d7f975859492",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4b3dda877954a51ac8f163b932ac664"
          }
        },
        "9715107e845241b7b6c683180f7c3b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64b39ef4df5e4c1e99290d66a00ba479",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6387309499,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6387309499,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_362a7451f44e42dd89753b7407877821"
          }
        },
        "a3f087b1e5fd4e1381ec0e1b80801b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60ba00c153084b5699ba52e464ce870f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.95G/5.95G [05:31&lt;00:00, 19.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_788245127c6f4be1af7c0f776a63d773"
          }
        },
        "210d445576ec438096e8d7f975859492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4b3dda877954a51ac8f163b932ac664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64b39ef4df5e4c1e99290d66a00ba479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "362a7451f44e42dd89753b7407877821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60ba00c153084b5699ba52e464ce870f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "788245127c6f4be1af7c0f776a63d773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcb8eaa18c794597bd6115c3df7eac8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20624b642a544e3dbbf4c192a17d5b0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbfe1c6434f640e490fdf0b2e1a19f3d",
              "IPY_MODEL_699b4368041540638a2e976c0ca343f7",
              "IPY_MODEL_05409ee7268a40cd8cbd8e54e84edce3"
            ]
          }
        },
        "20624b642a544e3dbbf4c192a17d5b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbfe1c6434f640e490fdf0b2e1a19f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb2911f94b2b42a0a7b1513a837bbda9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ff92a9407b4466f9d07e6972422fd43"
          }
        },
        "699b4368041540638a2e976c0ca343f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8c8481ce9054b3b9f7f58c2a7a88a46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a211c5dba2943b4bb4dee406621a4dd"
          }
        },
        "05409ee7268a40cd8cbd8e54e84edce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f1cb6395a1d49dfae131e2f89e0743c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:37&lt;00:00, 20.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d354b45d2344d579eb153aa5930affb"
          }
        },
        "eb2911f94b2b42a0a7b1513a837bbda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ff92a9407b4466f9d07e6972422fd43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8c8481ce9054b3b9f7f58c2a7a88a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a211c5dba2943b4bb4dee406621a4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f1cb6395a1d49dfae131e2f89e0743c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d354b45d2344d579eb153aa5930affb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "jnPzukuR_9by",
        "outputId": "92345f02-3bc6-483c-c469-8ea02c6ad864"
      },
      "source": [
        "pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.1\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 6.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torch, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1 torchaudio-0.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwIDQwgxmRug"
      },
      "source": [
        "# Importing all neccessary libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61I4t_DTVHYm"
      },
      "source": [
        "import warnings\n",
        "warnings. filterwarnings(\"ignore\")\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torchaudio import transforms as tfs\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from torch.nn import Sequential as sq\n",
        "from torch.nn import Linear as lnr\n",
        "from torch import argmax as agm\n",
        "from torch.nn import Module as ml\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYpRZD8mmy_-"
      },
      "source": [
        "# Evaluation Metrics implementation (WER and CER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Jsa6RhV7ES"
      },
      "source": [
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "  \n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        " \n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    def __init__(self):\n",
        "        self.char_map={\"'\": 0, '': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n",
        "        self.index_map={0: \"'\", 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n",
        "        \n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    \n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S03454e2nQ9p"
      },
      "source": [
        "## The NVIDIA System Management Interface (management and monitoring of NVIDIA GPU devices)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrzOZ5BgX8Ps",
        "outputId": "fe6fb007-9fdd-4daa-d18b-188228dbbc5f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM0mA41WneNT"
      },
      "source": [
        "# **CNN layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpObb3vXX_El"
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 3).contiguous() \n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x \n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUGjv3ounj3_"
      },
      "source": [
        "# **Gated Recurrent Unit layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqmUQLJYBI-"
      },
      "source": [
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupyNOdlno-Z"
      },
      "source": [
        "# Final Automatic Speech Recognition Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kIVttAsYDb5"
      },
      "source": [
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2) \n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  \n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3]) \n",
        "        x = x.transpose(1, 2) \n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y41lkdZ-noVh"
      },
      "source": [
        "# Training and Testing Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ8oZecBYGFi"
      },
      "source": [
        "class IterMeter(object):\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms) \n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "    \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  \n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "  \n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "    # filename='./best_fit_model'+str(epoch)+'.h5'\n",
        "    # torch.save(model,filename)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGj7rLijn4Q-"
      },
      "source": [
        "# Hyperparameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMG9JxM4YHaA"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 5\n",
        "epochs = 10\n",
        "train_url = \"train-clean-100\"\n",
        "test_url = \"test-clean\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "81c0dc5cd8ac477cbc425578cc09e349",
            "8df098629d5d4c169252983947a16421",
            "122c48c556e5404cbaf0f63fec20fd0e",
            "9715107e845241b7b6c683180f7c3b91",
            "a3f087b1e5fd4e1381ec0e1b80801b91",
            "210d445576ec438096e8d7f975859492",
            "c4b3dda877954a51ac8f163b932ac664",
            "64b39ef4df5e4c1e99290d66a00ba479",
            "362a7451f44e42dd89753b7407877821",
            "60ba00c153084b5699ba52e464ce870f",
            "788245127c6f4be1af7c0f776a63d773",
            "fcb8eaa18c794597bd6115c3df7eac8c",
            "20624b642a544e3dbbf4c192a17d5b0c",
            "dbfe1c6434f640e490fdf0b2e1a19f3d",
            "699b4368041540638a2e976c0ca343f7",
            "05409ee7268a40cd8cbd8e54e84edce3",
            "eb2911f94b2b42a0a7b1513a837bbda9",
            "5ff92a9407b4466f9d07e6972422fd43",
            "c8c8481ce9054b3b9f7f58c2a7a88a46",
            "4a211c5dba2943b4bb4dee406621a4dd",
            "8f1cb6395a1d49dfae131e2f89e0743c",
            "2d354b45d2344d579eb153aa5930affb"
          ]
        },
        "id": "0pUOYYKHYiCC",
        "outputId": "4836a11e-92f5-4ba2-b315-583e65fda361"
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81c0dc5cd8ac477cbc425578cc09e349",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcb8eaa18c794597bd6115c3df7eac8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4KvaBDgYKln",
        "outputId": "d2405b8c-1211-418a-ad9e-acc99bd0b209"
      },
      "source": [
        "hparams = {\n",
        "    \"n_cnn_layers\": 3,\n",
        "    \"n_rnn_layers\": 5,\n",
        "    \"rnn_dim\": 512,\n",
        "    \"n_class\": 29,\n",
        "    \"n_feats\": 128,\n",
        "    \"stride\":2,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs\n",
        "}\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(7)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=True,\n",
        "                            collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                            **kwargs)\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                            batch_size=hparams['batch_size'],\n",
        "                            shuffle=False,\n",
        "                            collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                            **kwargs)\n",
        "\n",
        "model = SpeechRecognitionModel(\n",
        "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "criterion = nn.CTCLoss(blank=28).to(device)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], steps_per_epoch=int(len(train_loader)),epochs=hparams['epochs'],anneal_strategy='linear')\n",
        "\n",
        "iter_meter = IterMeter()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n",
            "Num Model Parameters 23705373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxftuqFfo_tO"
      },
      "source": [
        "# Code for model training and testing (Optional)\n",
        "\n",
        "\n",
        "> This code snippet should only be used for base model training.\n",
        "\n",
        "> Since we already have our based model trained , we will skip this part and load our trained model directly\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C6FJgkro8I3"
      },
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "    train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
        "    test(model, device, test_loader, criterion, epoch, iter_meter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX0uozFvn--5"
      },
      "source": [
        "# Loading the best fit model\n",
        "\n",
        "\n",
        "*   The base model for slurred speech Recognition has been trained on kaggle for 10 epoch.\n",
        "*   It has been trained on Librispeech Corpus Speech Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGALiIQhZMwO"
      },
      "source": [
        "loaded_model = torch.load('/content/drive/MyDrive/BTP Datasets/Best_fit_model/best_fit_model10.h5',\n",
        "                          map_location=torch.device('cpu'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6gIyA4YgpQ",
        "outputId": "ee312115-8140-4e1f-83be-c4a76069bc55"
      },
      "source": [
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXebGeypl03"
      },
      "source": [
        "# Testing our loaded base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUkhKqGGpxol",
        "outputId": "80bb028e-de41-4e21-ee18-a4fac2a2a84d"
      },
      "source": [
        "test(loaded_model, device, test_loader, criterion, 1, iter_meter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.5171, Average CER: 0.119907 Average WER: 0.1413\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p8C5mpLbm20"
      },
      "source": [
        "import os\n",
        "from typing import Tuple, Union\n",
        "from pathlib import Path\n",
        "import torchaudio\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def load_librispeech_item(fileid,path,ext_audio,ext_txt):\n",
        "    speaker_id, chapter_id, utterance_id = fileid.split(\"-\")\n",
        "\n",
        "    file_text = speaker_id + \"-\" + chapter_id + ext_txt\n",
        "    file_text = os.path.join(path, speaker_id, chapter_id, file_text)\n",
        "\n",
        "    fileid_audio = speaker_id + \"-\" + chapter_id + \"-\" + utterance_id\n",
        "    file_audio = fileid_audio + ext_audio\n",
        "    file_audio = os.path.join(path, speaker_id, chapter_id, file_audio)\n",
        "\n",
        "    waveform, sample_rate = torchaudio.load(file_audio)\n",
        "\n",
        "    with open(file_text) as ft:\n",
        "        for line in ft:\n",
        "            fileid_text, utterance = line.strip().split(\" \", 1)\n",
        "            if fileid_audio == fileid_text:\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Translation not found for \" + fileid_audio)\n",
        "\n",
        "    return (waveform,sample_rate,utterance,int(speaker_id),int(chapter_id),int(utterance_id),)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNeuTm-IFr8x"
      },
      "source": [
        "## Custom class for loading Slurred Speech Test Dataset in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AWy9snF1WZ"
      },
      "source": [
        "class TestDataset(Dataset): \n",
        "    _ext_txt = \".trans.txt\"\n",
        "    _ext_audio = \".flac\"\n",
        "    def __init__(self):\n",
        "        self._path=\"/content/drive/MyDrive/BTP Datasets/SlurredSpeech_Dataset_Test\"\n",
        "        self._walker=['1-2-0000', '1-2-0001', '1-2-0002', '1-2-0003', '1-2-0004', '1-2-0005', '1-2-0006', '1-2-0007', '1-2-0008', '1-2-0009', '1-2-0010', '1-2-0011', '1-2-0012', '1-2-0013', '1-2-0014', '1-2-0015', '1-2-0016', '1-2-0017', '1-2-0018', '1-2-0019', '1-2-0020', '1-2-0021', '1-2-0022', '1-2-0023', '1-2-0024', '1-2-0025', '1-2-0026', '1-2-0027', '1-2-0028', '1-2-0029', '1-2-0030', '1-2-0031', '1-2-0032', '1-2-0033', '1-2-0034', '1-2-0035', '1-2-0036', '1-2-0037', '1-2-0038', '1-2-0039', '1-2-0040', '1-2-0041', '1-2-0042', '1-2-0043', '1-2-0044', '1-2-0045', '1-2-0046', '1-2-0047', '1-2-0048', '1-2-0049', '1-2-0050', '1-2-0051', '1-2-0052', '1-2-0053', '1-2-0054', '1-2-0055', '1-2-0056', '1-2-0057', '1-2-0058', '1-2-0059', '1-2-0060', '1-2-0061', '1-2-0062', '1-2-0063', '1-2-0064', '1-2-0065', '1-2-0066', '1-2-0067', '1-2-0068', '1-2-0069', '1-2-0070', '1-2-0071', '1-2-0072', '1-2-0073', '1-2-0074', '1-2-0075', '1-2-0076', '1-2-0077', '1-2-0078', '1-2-0079', '1-2-0080', '1-2-0081', '1-2-0082', '1-2-0083', '1-2-0084', '1-2-0085', '1-2-0086', '1-2-0087', '1-2-0088', '1-2-0089', '1-2-0090', '1-2-0091', '1-2-0092', '1-2-0093', '1-2-0094', '1-2-0095', '1-2-0096', '1-2-0097', '1-2-0098', '1-2-0099']\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        fileid = self._walker[n]\n",
        "        return load_librispeech_item(fileid, self._path, self._ext_audio, self._ext_txt)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._walker)   \n",
        "    \n",
        "    \n",
        "testDataset_slurred_speech=TestDataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-yHQfJhF4Is"
      },
      "source": [
        "## Custom class for loading Slurred Speech Train Dataset in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32vqme6tF_9D"
      },
      "source": [
        "class TrainDataset(Dataset): \n",
        "    _ext_txt = \".trans.txt\"\n",
        "    _ext_audio = \".flac\"\n",
        "    def __init__(self):\n",
        "        self._path=\"/content/drive/MyDrive/BTP Datasets/SlurredSpeech_Dataset_Train\"\n",
        "        self._walker=['1-2-0000', '1-2-0001', '1-2-0002', '1-2-0003', '1-2-0004', '1-2-0005', '1-2-0006', '1-2-0007', '1-2-0008', '1-2-0009', '1-2-0010', '1-2-0011', '1-2-0012', '1-2-0013', '1-2-0014', '1-2-0015', '1-2-0016', '1-2-0017', '1-2-0018', '1-2-0019', '1-2-0020', '1-2-0021', '1-2-0022', '1-2-0023', '1-2-0024', '1-2-0025', '1-2-0026', '1-2-0027', '1-2-0028', '1-2-0029', '1-2-0030', '1-2-0031', '1-2-0032', '1-2-0033', '1-2-0034', '1-2-0035', '1-2-0036', '1-2-0037', '1-2-0038', '1-2-0039', '1-2-0040', '1-2-0041', '1-2-0042', '1-2-0043', '1-2-0044', '1-2-0045', '1-2-0046', '1-2-0047', '1-2-0048', '1-2-0049', '1-2-0050', '1-2-0051', '1-2-0052', '1-2-0053', '1-2-0054', '1-2-0055', '1-2-0056', '1-2-0057', '1-2-0058', '1-2-0059', '1-2-0060', '1-2-0061', '1-2-0062', '1-2-0063', '1-2-0064', '1-2-0065', '1-2-0066', '1-2-0067', '1-2-0068', '1-2-0069', '1-2-0070', '1-2-0071', '1-2-0072', '1-2-0073', '1-2-0074', '1-2-0075', '1-2-0076', '1-2-0077', '1-2-0078', '1-2-0079', '1-2-0080', '1-2-0081', '1-2-0082', '1-2-0083', '1-2-0084', '1-2-0085', '1-2-0086', '1-2-0087', '1-2-0088', '1-2-0089', '1-2-0090', '1-2-0091', '1-2-0092', '1-2-0093', '1-2-0094', '1-2-0095', '1-2-0096', '1-2-0097', '1-2-0098', '1-2-0099']\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        fileid = self._walker[n]\n",
        "        return load_librispeech_item(fileid, self._path, self._ext_audio, self._ext_txt)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._walker)   \n",
        "    \n",
        "    \n",
        "trainDataset_slurred_speech=TrainDataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK8WOvO3bnAo"
      },
      "source": [
        "\n",
        "testDataLoaderSlurred = data.DataLoader(dataset=testDataset_slurred_speech,batch_size=hparams['batch_size'],shuffle=False,collate_fn=lambda x: data_processing(x, 'valid'),**kwargs)\n",
        "trainDataLoderSlurred = data.DataLoader(dataset=trainDataset_slurred_speech,batch_size=hparams['batch_size'],shuffle=False,collate_fn=lambda x: data_processing(x, 'valid'),**kwargs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpIbdbfbnGl",
        "outputId": "7407dc4c-82b5-4961-a8da-e68c2a37118f"
      },
      "source": [
        "test(loaded_model, device, testDataLoaderSlurred, criterion, 1, iter_meter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 4.3672, Average CER: 0.638808 Average WER: 0.6565\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTzv5UsFbnI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ff9bee-c9ef-4a0d-fd4a-e5519d00d038"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 3\n",
        "epochs = 10\n",
        "hparams = {\n",
        "    \"n_cnn_layers\": 3,\n",
        "    \"n_rnn_layers\": 5,\n",
        "    \"rnn_dim\": 512,\n",
        "    \"n_class\": 29,\n",
        "    \"n_feats\": 128,\n",
        "    \"stride\":2,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs\n",
        "}\n",
        "opti = optim.AdamW(loaded_model.parameters(), hparams['learning_rate'])\n",
        "crit = nn.CTCLoss(blank=28).to(device)\n",
        "sche = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], steps_per_epoch=int(len(trainDataLoderSlurred)),epochs=hparams['epochs'],anneal_strategy='linear')\n",
        "iter = IterMeter()\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train(loaded_model, device, trainDataLoderSlurred, crit, opti, sche, epoch, iter)\n",
        "    test(loaded_model, device, testDataLoaderSlurred, crit, epoch, iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/100 (0%)]\tLoss: 2.751189\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.6527, Average CER: 0.813115 Average WER: 0.6472\n",
            "\n",
            "Train Epoch: 2 [0/100 (0%)]\tLoss: 2.638107\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.4658, Average CER: 0.762509 Average WER: 0.6240\n",
            "\n",
            "Train Epoch: 3 [0/100 (0%)]\tLoss: 2.462271\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.2922, Average CER: 0.726978 Average WER: 0.6174\n",
            "\n",
            "Train Epoch: 4 [0/100 (0%)]\tLoss: 2.338079\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.0999, Average CER: 0.678265 Average WER: 0.5970\n",
            "\n",
            "Train Epoch: 5 [0/100 (0%)]\tLoss: 2.146507\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.8961, Average CER: 0.620740 Average WER: 0.5652\n",
            "\n",
            "Train Epoch: 6 [0/100 (0%)]\tLoss: 1.855584\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.7636, Average CER: 0.626785 Average WER: 0.5494\n",
            "\n",
            "Train Epoch: 7 [0/100 (0%)]\tLoss: 1.702025\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.5708, Average CER: 0.566753 Average WER: 0.4969\n",
            "\n",
            "Train Epoch: 8 [0/100 (0%)]\tLoss: 1.523568\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.4270, Average CER: 0.524797 Average WER: 0.4587\n",
            "\n",
            "Train Epoch: 9 [0/100 (0%)]\tLoss: 1.267949\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.2099, Average CER: 0.485265 Average WER: 0.4210\n",
            "\n",
            "Train Epoch: 10 [0/100 (0%)]\tLoss: 1.145709\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.1347, Average CER: 0.423623 Average WER: 0.4006\n",
            "\n"
          ]
        }
      ]
    }
  ]
}